---
layout: post
title:  "Knowledge graphs and wikidata subsetting"
date:   2021-04-02
tags: BH20EU
doi: 10.37044/osf.io/wu9et
wikidata: Q106697289
authors:
  - name: Jose Emilio Labra-Gayo
    orcid: 0000-0001-8907-5348
  - name: Alejandro González Hevia
  - name: Daniel Fernández Álvarez
  - name: Ammar Ammar
    orcid: 0000-0002-8399-8990
  - name: Dan Brickley
  - name: Alasdair J. G. Gray
    orcid: 0000-0002-5711-4872
  - name: Eric Prud'hommeaux
  - name: Denise Slenter
  - name: Harold Solbrig
  - name: Seyed Amir Hosseini Beghaeiraveri
    orcid: 0000-0002-9123-5686
  - name: Benno Fünkfstük
  - name: Andra Waagmeester
  - name: Egon Willighagen
    orcid: 0000-0001-7542-0286
  - name: Liza Ovchinnikova
  - name: Guillermo Benjaminsen
  - name: Roberto García González
  - name: Leyla Jael Castro
    orcid: 0000-0003-3986-0510
  - name: Daniel Mietchen
    orcid: 0000-0001-9488-1870
europepmc: PPR306546
---

Knowledge graphs have successfully been adopted by academia, governement and industry to represent large scale knowledge bases. Open and collaborative knowledge graphs such as Wikidata capture knowledge from different domains and harmonize them under a common format, making it easier for researchers to access the data while also supporting Open Science.Wikidata keeps getting bigger and better, which subsumes integration use cases. Having a large amount of data such as the one presented in a scopeless Wikidata offers some advantages, e.g., unique access point and common format, but also poses some challenges, e.g., performance.Regular wikidata users are not unfamiliar with running into frequent timeouts of submitted queries. Due to its popularity, limits have been imposed to allow for fair access to many.However this suppreses many interesting and complex queries that require more computational power and resources. Replicating Wikidata on one's own infrastructure can be a solution which also offers a snapshot of the contents of wikidata at some given point in time. There is no need to replicate Wikidata in full, it is possible to work with subsets targeting, for instance, a particular domain. Creating those subsets has emerged as an alternative to reduce the amount and spectrum of data offered by Wikidata. Less data makes more complex queries possible while still keeping the compatibility with the whole Wikidata as the model is kept.  In this paper we report the tasks done as part of a Wikidata subsetting project during the Virtual BioHackathon Europe 2020 and SWAT4(HC)LS 2021, which had already started at NBDC/DBCLS BioHackathon 2019 in Japan, SWAT4(HC)LS hackathon 2019, and Virtual COVID-19 BioHackathon 2019. We describe some of approaches we identified to create subsets and some susbsets from the Life Sciences domain as well as other use cases we also discussed.

